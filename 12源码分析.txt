源码的分析（目的）
3个环节 <- 分布式计算 <- 追求：
                        计算向数据移动
                        并行度、分治
                        数据本地化读取

Client：
    没有计算发生
    很重要：支撑了计算向数据移动和计算的并行度
    1. Checking the input and output specifications of the job.
    2. Computing the InputSplits for the job. // split    -> 并行度和计算向数据移动就可以实现了
    3. Setup the requisite accouting information for the DistrubtedCache of the job,    // 可以使用缓存或者内存的东西来加速
    4. Coping the job's jar and configuration to the map-reduce system directory on the distribute file system. // 将jar包和配置信息拷贝到分布式文件系统
    5. Submitting the job to the JobTracker and optionally monitoring it's status.

    MR框架默认的输入格式化类：TextInputFormat < FileInputFormat < InputFormat
                                            getSplits
        minSize = 1
        maxSize = Long.Max
        blockSize = file
        splitSize = Math.max(minSize, Math.min(maxSize, blockSize));    // 默认split大小等于块大小

        切片split是一个窗口机制：（调大split改小，调小split改大）
            如果我想得到一个比block大的split

        if((blockLocations[i].getOffset() <= offset) && (offset < blockLocations[i].getOffset() + blockLocations[i].getLength())

        split:  解耦  存储层和计算层
            1. file
            2. offset
            3. length
            4. hosts        // 之称的计算向数据移动


   MapTask:
    input -> map -> output
    input:(split+format)
        来自于我们输入的格式化类给我们实际返回的记录读取器对象
            TextInputFormat -> LineRecordReader
                split:file, offset, length
                init:
                    in = fs.open(file).seek(offset)
                    除了第一个切片对应的map，之后的map都在init环节，从切片包含的数据中，让出第一行，并把切片的起始位置更新为切片的第二行。换言之，前一个map会多读取一行，来弥补hdfs把数据切割的问题。
                nextKeyValue():
                    1. 读取数据中的一条记录对key，value赋值。
                    2. 返回布尔值
                getCurrentKey():
                getCurrentValue():



                output
                    MapOutputBuffer:
                            map输出的KV会序列化成字节数组，算出P，最终是3元组, K V P
                            buffer使用的是环形缓冲区：
                                1. 本质还是线性字节数组
                                2. 赤道，两端方向放KV，索引
                                3. 索引：是固定宽度，16B
                                    a)P
                                    b)KS
                                    c)VS
                                    d)VL
                                4. 如果数据填充到阈值：80%，启动线程：
                                    快速排序80%数据，同时map输出的线程向剩余的空间写
                                    快速排序的过程：是比较key排序，但是移动的是索引
                                5. 最终，溢写时只要按照排序的索引，卸下文件中的数据就是有序的
                                    注意：排序是二次排序
                                        分区有序：        最后reduce拉取是按照分区的
                                        分区内key有序：       因为reduce计算是按分组计算。分组的语义（相同的key排在了一起）。
                                6. 调优：combiner
                                    1. 其实就是一个map里的reduce
                                        按组统计
                                    2. 发生在哪个时间点：
                                        内存溢写数据之前，排序之后
                                            a)溢写的io变少
                                            b)最终map输出结束，输出过程中，buffer溢写出多个小文件（内部有序）
                                                minSpillsForCombine = 3  // 默认值，可以设置修改
                                                map最终会把溢写出来的小文件合并成一个大文件：避免小文件的碎片化对未来reduce拉取数据造成的随机读写
                                                也会触发combine
                                    3. combine注意：
                                        必须幂等
                                        例子：
                                            1. 求和计算
                        partitioner
                        collector
                        MapOutputBuffer:
                            init():
                                spillper = 0.8
                                sortmb = 100MB
                                sorter = QuickSort
                                comparator = job.getOutputKeyComparator();
                                    1. 优先取用户覆盖的自定义排序比较器
                                    2. 保底，取key这个类型自身的比较器。

                                combiner ? reduce
                                        minSpillsForCombine = 3  // 默认值，可以设置修改

                                SpillThread  // 溢写线程
                                sortAndSpill()  // 排序并且溢写


ReduceTask
    input -> reduce -> output
    map:run:        while(context.nextKeyValue())
                        一条记录调用一次map
    reduce:run:     while(context.nextKey())
                        一组数据调用一次reduce

    doc:
        1. shuffle:     洗牌（相同的key被拉取到一个分区），拉取数据。
        2. sort:     整个MR框架中只有map端是从无序到有序的过程，用的是快速排序。
                        reduce这里所谓的sort其实你可以想成就是一个对着map排好序的一堆小文件做归并排序的过程
                grouping comparator
                1970-1-22 33 bj
                1970-1-8  23 sh
                    排序比较啥：年、月、温度，，且温度倒序
                    分组比较器：年、月
        3. reduce：

        run:
            rIter = shuffle...      // reduce拉取回属于自己的数据，并包装成一个迭代器~！
                类比：file(磁盘上） -> open -> readline -> hasNext() -> next()
                时时刻刻想：我们做的是大数据计算，数据可能撑爆内存。
                comparator = job.getOutputValueGroupComparator();
                                    如果没有手工设置分组比较器，默认返回 getOutputKeyComparator();
                                        1. 优先取用户覆盖的自定义排序比较器
                                        2. 保底，取key这个类型自身的比较器。
                    #: 分组比较器可不可以复用排序比较器？
                        设么叫排序比较器：返回值： -1, 0, 1
                        什么叫做分组比较器：返回值：  布尔值，false/true
                        可以的，0相等，否则不等。

            rIter 相当于是input，真迭代器
            rIter最终会传入ReduceContextImpl中，相当于是我们自己写reduce程序的时候context.write的context实现类
            ReduceContextImpl:
                nextKey();
                nextKeyValue();
                    在这个方法中会用到input取数据
                    在这个方法中有几个变量需要注意下：
                        hasMore: 还有数据就代表为true
                        nextKeyIsSame = false;
                    在这个方法中做了几件事情：
                        1. 通过input取数据，对key和value赋值
                        2. 返回布尔值
                        3. reduce会多取一条数据判断更新nextKeyIsSame，窥探下一条记录是不是还是一组的。

                getCurrentKey():
                    return key;
                getValues();
                    return iterable;    // iterable 和 hasMore、nextKeyIsSame一样，都是ReduceContextImpl的成员变量; iterable = ValueIterable;
                        ValueIterable:
                            iterator():
                                return iterator;    // iterator = ValueIterator
                                    ValueIterator:  // 假迭代器：嵌套迭代器
                                        hasNext();
                                            return firstValue || nextKeyIsSame;
                                        next();
            **:
                reduceTask拉取回的数据被包装成一个迭代器
                reduce方法被调用的时候，并没有把一组数据真的加载到内存，而是传递了一个迭代器-values
                在reduce方法中使用这个迭代器的时候，hasNext方法判断nextKeyIsSame，下一条是不是还是一组数据
                next方法：负责调用nextKeyValue方法，从reduceTask级别的迭代器，并同时更新nextKeyIsSame

                以上的设计艺术：
                    充分利用了迭代器模式，
                    规避了内存数据OOM的问题，
                    且，之前不是说了框架是排序的，所以真假迭代器他们只需要协作，一次I/O就可以线性处理完每一组数据~！


mapTask 和 reduceTask的比较器比较：
mapTask:
1. 优先取用户定义的排序比较器
2. 取key自身的排序比较器

reduceTask:
1. 取用户自定义的分组比较器
2. 取用户定义的排序比较器
3. 取key自身的排序比较器

组合方式：
    1) 用户不设置排序和分组比较器；
        map：取key自身的排序比较器
        reduce：取key自身的排序比较器
    2）设置了排序，没有设置分组：
        map：取用户定义的排序比较器
        reduce：取用户定义的排序比较器
    3）设置了分组
        map：取key自身的排序比较器
        reduce：取用户自定义的分组比较器
    4）设置了排序和分组
        map：取用户定义的排序比较器
        reduce：取用户自定义的分组比较器

结论：框架很灵活，给了我们各种加工数据排序和分组的方式